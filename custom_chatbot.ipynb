{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "In this project, we intend to utilize an LLM for question answering task related to the major events that happened in the year 2023. The LLM selected for this project is OpenAI ['gpt-3.5-turbo-instruct'](https://platform.openai.com/docs/models/gpt-3-5-turbo) but its training data is only up to September 2021 and hence, it is not aware of the 2023 events. To provide this relevant 2023 context to our chosen LLM, we utilize [2023 Wikipedia page](https://en.wikipedia.org/wiki/2023) and we access this data via [Wikipedia API](https://www.mediawiki.org/wiki/API:Main_page). This Wiki page contains brief extracts of most major events that happened in 2023 which makes it highly relevant for our intended purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In the cells below, we load our chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of our text data as well as their corresponding embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Get the Wikipedia page for \"2023\" since OpenAI's models stop in 2021\n",
    "params = {\n",
    "    \"action\": \"query\", \n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": \"2023\",\n",
    "    \"explaintext\": 1,\n",
    "    \"formatversion\": 2,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
    "response_dict = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text\n",
      "0   2023 (MMXXIII) was a common year starting on S...\n",
      "1   The year 2023 saw the decline in severity of t...\n",
      "2   The Russian invasion of Ukraine and Myanmar ci...\n",
      "3   A banking crisis resulted in the collapse of n...\n",
      "4   In the realm of technology, 2023 saw the conti...\n",
      "11  January 1 – Croatia adopts the euro and joins ...\n",
      "12  January 5 – The funeral of Pope Benedict XVI i...\n",
      "13                                          January 8\n",
      "14  The 2023 Beninese parliamentary election is he...\n",
      "15  Following the 2022 Brazilian general election ...\n",
      "16  January 9 – Juliaca massacre: At least 18 peop...\n",
      "17  January 10–17 – A cold snap in Afghanistan kil...\n",
      "18  January 15 – Yeti Airlines Flight 691 crashes ...\n",
      "19  January 16 – Tigray War: Amharan Special Force...\n",
      "20  January 17 – Nguyễn Xuân Phúc resigns as Presi...\n",
      "21  January 18 – A helicopter crash in Brovary nea...\n",
      "22  January 20 – The Parliament of Trinidad and To...\n",
      "23                                         January 21\n",
      "24  Burkina Faso requests French forces to withdra...\n",
      "25  Tigray War: Eritrean forces withdraw from Shir...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "print(df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text\n",
      "0    – 2023 (MMXXIII) was a common year starting o...\n",
      "1   The year 2023 saw the decline in severity of t...\n",
      "2    – The Russian invasion of Ukraine and Myanmar...\n",
      "3    – A banking crisis resulted in the collapse o...\n",
      "4    – In the realm of technology, 2023 saw the co...\n",
      "11  January 1 – Croatia adopts the euro and joins ...\n",
      "12  January 5 – The funeral of Pope Benedict XVI i...\n",
      "14  January 8 – The 2023 Beninese parliamentary el...\n",
      "15  January 8 – Following the 2022 Brazilian gener...\n",
      "16  January 9 – Juliaca massacre: At least 18 peop...\n",
      "17  January 10–17 – A cold snap in Afghanistan kil...\n",
      "18  January 15 – Yeti Airlines Flight 691 crashes ...\n",
      "19  January 16 – Tigray War: Amharan Special Force...\n",
      "20  January 17 – Nguyễn Xuân Phúc resigns as Presi...\n",
      "21  January 18 – A helicopter crash in Brovary nea...\n",
      "22  January 20 – The Parliament of Trinidad and To...\n",
      "24  January 21 – Burkina Faso requests French forc...\n",
      "25  January 21 – Tigray War: Eritrean forces withd...\n",
      "26  January 25 – Chris Hipkins succeeds Jacinda Ar...\n",
      "27  January 27 – Widespread unrest erupts in Israe...\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")]\n",
    "print(df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "In the cells below, we compose a custom query using our chosen dataset and retrieve results from an OpenAI `Completion` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0    – 2023 (MMXXIII) was a common year starting o...   \n",
      "1   The year 2023 saw the decline in severity of t...   \n",
      "2    – The Russian invasion of Ukraine and Myanmar...   \n",
      "3    – A banking crisis resulted in the collapse o...   \n",
      "4    – In the realm of technology, 2023 saw the co...   \n",
      "11  January 1 – Croatia adopts the euro and joins ...   \n",
      "12  January 5 – The funeral of Pope Benedict XVI i...   \n",
      "14  January 8 – The 2023 Beninese parliamentary el...   \n",
      "15  January 8 – Following the 2022 Brazilian gener...   \n",
      "16  January 9 – Juliaca massacre: At least 18 peop...   \n",
      "17  January 10–17 – A cold snap in Afghanistan kil...   \n",
      "18  January 15 – Yeti Airlines Flight 691 crashes ...   \n",
      "19  January 16 – Tigray War: Amharan Special Force...   \n",
      "20  January 17 – Nguyễn Xuân Phúc resigns as Presi...   \n",
      "21  January 18 – A helicopter crash in Brovary nea...   \n",
      "22  January 20 – The Parliament of Trinidad and To...   \n",
      "24  January 21 – Burkina Faso requests French forc...   \n",
      "25  January 21 – Tigray War: Eritrean forces withd...   \n",
      "26  January 25 – Chris Hipkins succeeds Jacinda Ar...   \n",
      "27  January 27 – Widespread unrest erupts in Israe...   \n",
      "\n",
      "                                           embeddings  \n",
      "0   [0.011585609056055546, -0.031669482588768005, ...  \n",
      "1   [0.018188100308179855, 0.03873858600854874, 0....  \n",
      "2   [-0.06412089616060257, 0.0033882565330713987, ...  \n",
      "3   [-0.013411029241979122, -0.030569257214665413,...  \n",
      "4   [0.026942692697048187, 0.0007336187991313636, ...  \n",
      "11  [-0.05088939890265465, -0.01587575301527977, 0...  \n",
      "12  [0.010895968414843082, -0.013372752815485, 0.0...  \n",
      "14  [0.018735522404313087, -0.03675586357712746, 0...  \n",
      "15  [0.019703758880496025, -0.018963173031806946, ...  \n",
      "16  [0.012851919047534466, -0.01858443021774292, 0...  \n",
      "17  [0.000721917487680912, 0.012269245460629463, 0...  \n",
      "18  [-0.021560480818152428, -7.927124534035102e-05...  \n",
      "19  [0.01785418391227722, -0.011529418639838696, 0...  \n",
      "20  [-0.023602010682225227, 0.005443388596177101, ...  \n",
      "21  [-0.051512859761714935, 0.000611197086982429, ...  \n",
      "22  [0.04017966613173485, -0.046738240867853165, 0...  \n",
      "24  [-0.0073321303352713585, -0.003925230819731951...  \n",
      "25  [0.00307646207511425, -0.03328385576605797, 0....  \n",
      "26  [0.019846346229314804, -0.02865389734506607, 0...  \n",
      "27  [-0.00015677606279496104, 0.01732845976948738,...  \n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from config import OpenAI_key\n",
    "openai.api_key = OpenAI_key\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\" #Increased performance over 2nd generation ada embedding model\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "print(df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "In the cells below, we demonstrate the performance of our custom query using 2 questions. For each question, we show the answer from a basic `Completion` model query as well as the answer from our custom query. The efficacy of the selected dataset is evident from the accurate LLM responses after providing it relevant context via RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I cannot answer this question as it is currently the year 2021 and it has not yet reached 2023. Additionally, I do not have access to information about potential future events.\n"
     ]
    }
   ],
   "source": [
    "Q1_prompt = \"\"\"\n",
    "Question: \"How many people were killed in 2023 Hawaii wildfires?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_Q1_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=Q1_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_Q1_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least 101 people were killed in the 2023 Hawaii wildfires.\n"
     ]
    }
   ],
   "source": [
    "custom_Q1_answer = answer_question(\"How many people were killed in 2023 Hawaii wildfires?\", df)\n",
    "print(custom_Q1_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tharman Shanmugaratnam has never been the president of Singapore. He has held various ministerial positions, including Deputy Prime Minister and Minister for Finance, but not the presidency. The current president of Singapore is Halimah Yacob, who has been in office since September 2017.\n"
     ]
    }
   ],
   "source": [
    "Q2_prompt = \"\"\"\n",
    "Question: \"When did Tharman become president of Singapore?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_Q2_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=Q2_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_Q2_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 1, 2023\n"
     ]
    }
   ],
   "source": [
    "custom_Q2_answer = answer_question(\"When did Tharman become president of Singapore?\", df)\n",
    "print(custom_Q2_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f02097a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: How many people were killed in 2023 Hawaii wildfires?\n",
      "\n",
      "Original Answer: I'm sorry, I cannot answer this question as it is currently the year 2021 and it has not yet reached 2023. Additionally, I do not have access to information about potential future events.\n",
      "Custom Answer:   At least 101 people were killed in the 2023 Hawaii wildfires.\n",
      "\n",
      "Q2: When did Tharman become president of Singapore?\n",
      "Original Answer: Tharman Shanmugaratnam has never been the president of Singapore. He has held various ministerial positions, including Deputy Prime Minister and Minister for Finance, but not the presidency. The current president of Singapore is Halimah Yacob, who has been in office since September 2017.\n",
      "Custom Answer:   September 1, 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Q1: How many people were killed in 2023 Hawaii wildfires?\n",
    "\n",
    "Original Answer: {initial_Q1_answer}\n",
    "Custom Answer:   {custom_Q1_answer}\n",
    "\n",
    "Q2: When did Tharman become president of Singapore?\n",
    "Original Answer: {initial_Q2_answer}\n",
    "Custom Answer:   {custom_Q2_answer}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
